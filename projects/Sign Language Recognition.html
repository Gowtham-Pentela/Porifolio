<!DOCTYPE html>
<html lang="en">
<head>
    <meta charset="UTF-8">
    <meta name="viewport" content="width=device-width, initial-scale=1.0">
    <title>Sign Language Recognition using CNN</title>
    <style>
        body {
            font-family: Arial, sans-serif;
            margin: 0;
            padding: 20px;
            background-color: #f4f4f9;
        }
        h1, h2, h3 {
            color: #333;
        }
        p {
            color: #555;
            line-height: 1.6;
        }
        code {
            background-color: #f0f0f0;
            padding: 2px 4px;
            font-family: monospace;
        }
        pre {
            background-color: #f0f0f0;
            padding: 10px;
            overflow-x: auto;
        }
        ul {
            list-style-type: none;
        }
        ul li {
            margin-bottom: 10px;
        }
        .code-block {
            background-color: #f9f9f9;
            border-left: 4px solid #e74c3c;
            padding: 10px;
        }
        .github-link {
            text-align: center;
            margin-top: 20px;
        }
        .github-link a {
            font-size: 16px;
            color: white;
            background-color: #24292f;
            padding: 10px 20px;
            text-decoration: none;
            border-radius: 5px;
        }
        .github-link a:hover {
            background-color: #444c55;
        }
    </style>
</head>
<body>

    <h1>Sign Language Recognition using CNN</h1>
    
    <p>This project focuses on developing a Convolutional Neural Network (CNN) to recognize American Sign Language (ASL) letters from images. The dataset contains grayscale images of hand signs representing different letters, and the model has achieved an impressive <strong>99.023% accuracy</strong> on the test dataset.</p>
    
    <h2>Dataset</h2>
    <ul>
        <li><strong>Train Dataset:</strong> <code>sign_mnist_train.csv</code></li>
        <li><strong>Test Dataset:</strong> <code>sign_mnist_test.csv</code></li>
    </ul>
    <p>The images are 28x28 pixels in grayscale with corresponding labels representing different sign language letters.</p>
    
    <h2>Libraries Used</h2>
    <ul>
        <li><strong>Pandas</strong>: For data manipulation</li>
        <li><strong>Numpy</strong>: For numerical computations</li>
        <li><strong>Seaborn & Matplotlib</strong>: For visualizations</li>
        <li><strong>Scikit-learn</strong>: For data preprocessing and train-test splitting</li>
        <li><strong>TensorFlow/Keras</strong>: For building and training the neural network</li>
        <li><strong>Visualkeras</strong>: For visualizing the model layers</li>
        <li><strong>ImageDataGenerator</strong>: For real-time data augmentation</li>
    </ul>
    
    <h2>Model Architecture</h2>
    <ul>
        <li><strong>Input Shape:</strong> 28x28x1 (grayscale images)</li>
        <li><strong>Convolution Layers:</strong> 2 Conv2D layers with ReLU activation and batch normalization</li>
        <li><strong>Pooling Layers:</strong> MaxPooling layers to reduce spatial size</li>
        <li><strong>Dropout:</strong> To reduce overfitting</li>
        <li><strong>Fully Connected Layer:</strong> Dense layer with 24 output units and softmax activation for classification</li>
    </ul>
    
    <h2>Preprocessing</h2>
    <ul>
        <li><strong>Normalization:</strong> Pixel values are scaled to the range [0, 1]</li>
        <li><strong>Label Binarization:</strong> Labels are one-hot encoded</li>
        <li><strong>Data Augmentation:</strong> Random rotations, zooms, width and height shifts</li>
    </ul>
    
    <h2>Model Performance</h2>
    <ul>
        <li><strong>Accuracy:</strong> 99.023%</li>
        <li><strong>Loss Function:</strong> Categorical Crossentropy</li>
        <li><strong>Optimizer:</strong> Adam</li>
        <li><strong>Learning Rate Schedule:</strong> ReduceLROnPlateau callback used to adjust learning rate when the validation accuracy plateaus</li>
    </ul>
    
    <h2>Training and Validation</h2>
    <p>The model was trained for 10 epochs with a batch size of 128. Training and validation accuracy and loss curves are visualized to assess the performance.</p>
    
    <h2>Installation</h2>
    <pre><code>pip install numpy pandas seaborn matplotlib tensorflow visualkeras scikit-learn</code></pre>
    
    <h2>How to Run</h2>
    <ol>
        <li>Place the <code>sign_mnist_train.csv</code> and <code>sign_mnist_test.csv</code> in the dataset directory.</li>
        <li>Run the Python script to preprocess data, train the model, and visualize results.</li>
        <li>The final accuracy will be printed after training, along with training/validation plots.</li>
    </ol>
    
    <h2>Future Improvements</h2>
    <ul>
        <li>Implement further hyperparameter tuning to enhance the model's performance.</li>
        <li>Explore deeper architectures or transfer learning techniques for higher accuracy.</li>
    </ul>

    <div class="github-link">
        <a href="https://github.com/Gowtham-Pentela/Sign-Language-dataset.git" target="_blank">View Source Code</a>
    </div>

</body>
</html>
